import numpy as np
import torch
from torch.backends import cudnn
from torch.utils.data import DataLoader
import torchvision
from torchvision import transforms
import torch.nn.functional as F
import argparse
import torchvision.models as models
from self_model import resnet_50_prm
from self_data import data
from self_tool import torchutils, pyutils

def validate(model, data_loader):
    print('\nvalidating ... ', flush=True, end='')

    val_loss_meter = pyutils.AverageMeter('loss')

    model.eval()
    model.inference()

    with torch.no_grad():
        for pack in data_loader:
            img = pack[1]
            label = pack[2].cuda(non_blocking=True)

            x = model(img)
            loss = F.multilabel_soft_margin_loss(x, label)

            val_loss_meter.add({'loss': loss.item()})

    model.train()

    print('loss:', val_loss_meter.pop('loss'))

    return

parser = argparse.ArgumentParser()
parser.add_argument("--batch_size", default=4, type=int)
parser.add_argument("--max_epoches", default=20, type=int)
parser.add_argument("--lr", default=0.0001, type=float)
parser.add_argument("--momentum", default=0.9, type=float)
parser.add_argument("--num_workers", default=8, type=int)
parser.add_argument("--wt_dec", default = 1.0e-4, type = float)
parser.add_argument("--weights", default = None, type = str)
parser.add_argument("--train_list", default="/home/zxforchid/Hu_Z/PRM-pytorch/demo/datasets/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt", type=str)
parser.add_argument("--val_list", default="/home/zxforchid/Hu_Z/PRM-pytorch/demo/datasets/VOCdevkit/VOC2012/ImageSets/Segmentation/val.txt", type=str)
parser.add_argument("--voc12_root", default="/home/zxforchid/Hu_Z/pychram_PRM/clear_stage", type = str)
parser.add_argument("--session_name", default="PRM_clear_5_peak", type=str)
args = parser.parse_args()

backbone = resnet_50_prm.ResNet50()
model = resnet_50_prm.Peak_Response_Map(backbone)

transformer = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((448, 448)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
])

train_dataset = data.VOC12ClsDataset(args.train_list, voc12_root = args.voc12_root, transform = transformer)

train_data_loader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle =True, num_workers = args.num_workers, pin_memory = True, drop_last = True)

max_step = (len(train_dataset) // args.batch_size) * args.max_epoches

val_dataset = data.VOC12ClsDataset(args.val_list, voc12_root = args.voc12_root, transform = transformer)

val_data_loader = DataLoader(val_dataset, batch_size=args.batch_size,
                                 shuffle=False, num_workers=args.num_workers, pin_memory=True, drop_last=True)

optimizer = torchutils.PolyOptimizer(
    [{'params': model[0].features.parameters(), 'lr': 0.0001, 'weight_decay': args.wt_dec, 'momentum': args.momentum},
     {'params': model[0].classifier.parameters(), 'lr': 0.01, 'weight_decay': args.wt_dec, 'momentum': args.momentum}],
    lr = args.lr, weight_decay = args.wt_dec,momentum = args.momentum, max_step = max_step
)

if args.weights is not None:
    state = torch.load(args.weights)
else:
    state = models.resnet50(pretrained=True).state_dict()
model.load_state_dict(state, strict = False)
model = torch.nn.DataParallel(model)
model = model.cuda()
model.train()

avg_meter = pyutils.AverageMeter('loss')

for ep in range(args.max_epoches):

    print("epoch%d:" % (ep))

    for iter, pack in enumerate(train_data_loader):

        img = pack[1].cuda().requires_grad_()
        label = pack[2].cuda(non_blocking=True)

        x = model(img)
        loss = F.multilabel_soft_margin_loss(x, label, None, size_average=True, reduce=True)

        avg_meter.add({'loss': loss.item()})

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (optimizer.global_step-1) % 50 == 0:

            print('Iter:%5d/%5d' % (optimizer.global_step - 1, max_step),
                  'Loss:%.4f' % (avg_meter.pop('loss')),
                  'lr: %.4f' % (optimizer.param_groups[0]['lr']), flush=True)

    # else:
        # validate(model, val_data_loader)

torch.save(model.module.state_dict(), args.session_name + '.pth')
